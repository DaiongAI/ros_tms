<!DOCTYPE html>
<html>
<head>
  <meta charset='utf-8'>
  <meta content="chrome=1" http-equiv="X-UA-Compatible">
  <meta content="width=device-width, initial-scale=1, maximum-scale=1" name="viewport">
  <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
  <link href="stylesheets/stylesheet.css" media="screen" rel="stylesheet" type="text/css">
  <link href="stylesheets/pygment_trac.css" media="screen" rel="stylesheet" type="text/css">
  <link href="stylesheets/print.css" media="print" rel="stylesheet" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <title>ROS-TMS by IRVS Lab.</title>
</head>

<body>

  <header>
    <div class="inner">
      <h1>ROS-TMS</h1>
      <h2>It is a service robot system with an informationally structured environment referred to the ROS-TMS.This system enables the integration of various data from distributed sensors, as well as storage of these data in an on-line database and the planning of the service motion of a robot using real-time information about the surroundings.</h2>
      <a class="button" href="https://github.com/irvs/ros_tms"><small>View project on</small> GitHub</a>
    </div>
  </header>

  <div id="content-wrapper">
    <div class="inner clearfix">
      <section id="main-content">


        <h3><a class="anchor" href="#page1" id="page1"><span class="octicon octicon-link"></span></a>
            環境情報構造化
        </h3>
        <p>日常生活環境でロボットが人間と共生して働くためには，ロボットに搭載された機能だけで複雑な周囲状況を認識するのではなく， 環境側にセンサネットワークや様々な情報を格納したマーカを配置して，ロボットの作業を支援する仕組みの構築が不可欠です．そこで，この仕組みを実現する環境情報構造化プラットフォームの研究開発を行っています．</p>
        <img src="images/robottown_concept.png">


        <h3><a class="anchor" href="#page1" id="page1"><span class="octicon octicon-link"></span></a>
            タウンマネジメントシステム（TMS）
        </h3>
        <p>情報構造化環境では，人やロボット，日用品の位置情報などを取得できます．さらに，ロボットが状況に対応して自動的にサービスを実行するためには，収集した情報を解釈し，適切なサービスを選択・実行する必要があります．また，大規模化するシステムに対応するため，センサや処理アルゴリズムをネットワーク化し，目的ごとに構成を組み替えられるものである必要もあります．これらの要件を満たしたTMSアーキテクチャを設計・開発し，実世界で生活支援サービスを提供するための研究を行っています．</p>
        <img src="images/tms.jpg">

        <h4>環境情報構造化に基づくサービスロボット実現のためのセンサ情報ネットワークの開発</h4>
        <p>環境側に分散配置された様々なセンサや処理アルゴリズムをネットワーク化し，目的ごとに構成を組み変えて必要な情報を取得，処理するとともに，結果をクラウド型データベースに格納します．その環境情報をサービスロボットに提供するシステムを開発しています． </p>
        <img src="images/system.png">

        <h4>情報構造化アーキテクチャの構築</h4>
        <p>ロボットの動作を支援するための環境である情報構造化環境では，環境にセンサを配置することで，人，ロボット，日用品の位置情報，環境地図などを取得することができます． さらに，ロボットが適切な生活支援サービスを実行するためには，集めた情報を統合・解釈し，環境内の状況を推定する必要があります． このように，情報構造化アーキテクチャの要件を明らかにし，実世界で生活支援サービスを提供する仕組みを構築するために研究を行っています． </p>
        <table width="90%">
          <tbody>
            <tr>
              <th class="bg" width="50%">日用品の物品管理サービス</th>
              <th class="bg" width="50%">倒れた人の検出･警告サービス</th>
            </tr>
            <tr>
              <td align="center"><img src="images/an_1.png" alt="photo" height="150"><br></td>
              <td align="center"><img src="images/an_2.png" alt="photo" height="150"><br></td>
            </tr>
          </tbody>
        </table>

        <h3><a class="anchor" href="#page1" id="page1"><span class="octicon octicon-link"></span></a>
            生活支援ロボットの行動動作計画
        </h3>
        <p>情報構造化された環境において，ワゴンを押して物品運搬を行うための動作計画を行っています．人に物品を手渡す位置や，ワゴンを押して移動するための経路の計画を行い，実機で検証します． </p>
        <img src="images/kn_1.png" alt="photo"><br>
        <iframe src="https://docs.google.com/file/d/0ByyF7QlkYfbUTmp3dzhHNjZjekk/preview" height="400" width="600"></iframe>

        <h3><a class="anchor" href="#page1" id="page1"><span class="octicon octicon-link"></span></a>
            Intelligent cabinet system
        </h3>
        <p>The cabinets installed in the room are equipped with RFID readers and load cells to detect the types and positions of the objects in the cabinet.
        Every object in the environment has an RFID tag containing a unique ID that identifies it.
        This ID is used to retrieve the attributes of the object, such as its name and location in the database.
        Using the RFID readers, we can detect the presence of a new object inside the cabinet.
        In addition, the load cell information allows us to determine its exact position inside the cabinet.
        An example of object detection in the intelligent cabinet is shown in below figure.
        </p>
        <iframe src="https://docs.google.com/file/d/0ByyF7QlkYfbUdE5uZFlpd09YWTA/preview" height="400" width="600"></iframe>

        <h3><a class="anchor" href="#page1" id="page1"><span class="octicon octicon-link"></span></a>
          Object detection system
        </h3>
        <p>If neither the FSS nor the ICS is available for detecting objects such as those placed on a desk, the object detection system using a RGB-D camera on a robot is provided in this platform as shown in below figure.
        In this system, a newly appeared object or movement of an object is detected as a change in the environment. </p>
        <table width="90%">
          <tbody>
            <tr><th class="bg" width="100%">本棚内の変化検出</th></tr>
            <tr><td align="center"><img src="images/sk.png" alt="photo" height="250"><br></td></tr>
          </tbody>
        </table>

        <h3><a class="anchor" href="#page1" id="page1"><span class="octicon octicon-link"></span></a>
          Floor sensing system (FSS)
        </h3>
        <p>The current platform is equipped with a floor sensing system to detect objects on the floor and people walking around.
        This sensing systems is composed of a laser range finder located on one side of the room and a mirror installed along another side of the room.
        This configuration allows a reduction of dead angles of the LRF and is more robust against occlusions.
        An example of object detection using this system is shown in below.
        People tracking is performed by first applying static background subtraction and then extracting clusters in the remainder of the measurements.
        Clusters are later tracked by matching profiles of cluster corresponding to legs and extending the motion using the accelerations of the legs.
        Moreover, this system can measure the poses of the robot and movable furniture such as a wagon using tags, which have encoded reflection patterns optically identified by the LRF.

        </p>
        <iframe src="https://docs.google.com/file/d/0ByyF7QlkYfbUeEJjQlBZbzZtenM/preview" height="400" width="600"></iframe><br>
        <img src="images/kku_2.png" alt="photo"><br>

<!--         <pre>
          <code>
          $ cd your_repo_root/repo_name
          $ git fetch origin
          $ git checkout gh-pages
          </code>
        </pre> -->


      </section>

      <aside id="sidebar">
        <a class="button" href="https://github.com/irvs/ros_tms/zipball/master"><small>Download</small> .zip file</a>
        <a class="button" href="https://github.com/irvs/ros_tms/tarball/master"><small>Download</small> .tar.gz file</a>

        <p class="repo-owner">
            <a href="https://github.com/irvs/ros_tms">ROS-TMS</a> is maintained by <a href="https://github.com/irvs">IRVS Lab.</a>
        </p>

        <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
      </aside>
    </div>
  </div>
</body>
</html>